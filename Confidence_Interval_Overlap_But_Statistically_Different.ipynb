{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When the confidence intervals of two groups overlap, it generally suggests that there is no statistically significant difference between the groups. However, there are scenarios where overlapping confidence intervals can still indicate statistical differences. Here are a few possibilities:\n",
    "\n",
    "Sample size: If the sample size of the groups is small, even a small difference between the groups may result in overlapping confidence intervals. In such cases, the overlapping intervals do not necessarily imply that there is no difference. Increasing the sample size can provide more precise estimates and potentially reveal statistically significant differences.\n",
    "\n",
    "Variability: If the variability within each group is large, it can lead to wider confidence intervals, increasing the chances of overlap. However, if the difference between the group means is substantial relative to the variability, a statistically significant difference may still exist despite the overlap.\n",
    "\n",
    "Hypothesis test: Confidence intervals and hypothesis tests provide different perspectives on comparing groups. While overlapping confidence intervals suggest no significant difference, a hypothesis test may detect a statistically significant difference based on the chosen significance level (e.g., 0.05). Hypothesis tests assess the likelihood of observing the data under the assumption of no difference between the groups.\n",
    "\n",
    "Directional hypotheses: In some cases, the research question may involve a directional hypothesis, where you expect one group to be consistently higher or lower than the other. In such situations, overlapping confidence intervals might still support a statistically significant difference if the observed values consistently align with the directional hypothesis.\n",
    "\n",
    "Multiple comparisons: If you are comparing multiple groups pairwise, the chances of observing overlapping confidence intervals increase. In such cases, adjusting for multiple comparisons using appropriate methods (e.g., Bonferroni correction) can help determine if any statistically significant differences exist.\n",
    "\n",
    "It's important to interpret overlapping confidence intervals cautiously and consider additional factors, such as sample size, variability, hypothesis tests, directional hypotheses, and multiple comparisons, to assess the potential for statistical differences between groups. Consulting with a statistician can provide valuable insights specific to your experiment and help determine the appropriate interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z stat:  -1.3880858307767148\n",
      "p value:  0.16511091065405215\n",
      "There is no significant difference between the groups.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Specify the number of successes (events of interest) and the sample size for each group\n",
    "successes_a = 60  # Number of successes in Group A\n",
    "n_a = 500        # Sample size of Group A\n",
    "\n",
    "successes_b = 75  # Number of successes in Group B\n",
    "n_b = 500        # Sample size of Group B\n",
    "\n",
    "# Perform the two-proportion z-test\n",
    "successes = [successes_a, successes_b]\n",
    "samples = [n_a, n_b]\n",
    "z_stat, p_value = proportions_ztest(successes, samples)\n",
    "print('z stat: ', z_stat)\n",
    "print('p value: ',  p_value)\n",
    "\n",
    "# Check if the p-value is less than the significance level (e.g., 0.05)\n",
    "significance_level = 0.05\n",
    "if p_value < significance_level:\n",
    "    print(\"The groups are statistically different.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the groups.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.stats import proportion_confint\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marigin of Error:  0.0285\n",
      "p_a:  0.12\n",
      "Confidence Interval: [0.0915, 0.1485]\n"
     ]
    }
   ],
   "source": [
    "# Specify the number of successes (events of interest) and the sample size for each group\n",
    "successes_a = 60  # Number of successes in Group A\n",
    "n_a = 500        # Sample size of Group A\n",
    "\n",
    "successes_b = 75  # Number of successes in Group B\n",
    "n_b = 500        # Sample size of Group B\n",
    "\n",
    "# Calculate the proportion (success rate) for each group\n",
    "p_a = successes_a / n_a\n",
    "p_b = successes_b / n_b\n",
    "\n",
    "# Calculate the margin of error and the confidence interval at a desired confidence level\n",
    "confidence_level = 0.95\n",
    "lower_bound, upper_bound = proportion_confint(successes_a, n_a, alpha=1-confidence_level, method='normal')\n",
    "\n",
    "# # Calculate the lower and upper bounds of the confidence interval\n",
    "# lower_bound = p_b - margin_of_error\n",
    "# upper_bound = p_b + margin_of_error\n",
    "\n",
    "# Print the margin of error and the confidence interval\n",
    "#print(\"Margin of Error: {:.4f}\".format(margin_of_error))\n",
    "print('Marigin of Error: ', round((upper_bound-p_a),4) )\n",
    "print('p_a: ', p_a)\n",
    "print(\"Confidence Interval: [{:.4f}, {:.4f}]\".format(lower_bound, upper_bound))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marigin of Error:  0.0313\n",
      "p_b:  0.15\n",
      "Confidence Interval: [0.1187, 0.1813]\n"
     ]
    }
   ],
   "source": [
    "# Specify the number of successes (events of interest) and the sample size for each group\n",
    "successes_a = 60  # Number of successes in Group A\n",
    "n_a = 500        # Sample size of Group A\n",
    "\n",
    "successes_b = 75  # Number of successes in Group B\n",
    "n_b = 500        # Sample size of Group B\n",
    "\n",
    "# Calculate the proportion (success rate) for each group\n",
    "p_a = successes_a / n_a\n",
    "p_b = successes_b / n_b\n",
    "\n",
    "# Calculate the margin of error and the confidence interval at a desired confidence level\n",
    "confidence_level = 0.95\n",
    "lower_bound, upper_bound = proportion_confint(successes_b, n_b, alpha=1-confidence_level, method='normal')\n",
    "\n",
    "# # Calculate the lower and upper bounds of the confidence interval\n",
    "# lower_bound = p_b - margin_of_error\n",
    "# upper_bound = p_b + margin_of_error\n",
    "\n",
    "# Print the margin of error and the confidence interval\n",
    "#print(\"Margin of Error: {:.4f}\".format(margin_of_error))\n",
    "print('Marigin of Error: ', round((upper_bound-p_b),4) )\n",
    "print('p_b: ', p_b)\n",
    "print(\"Confidence Interval: [{:.4f}, {:.4f}]\".format(lower_bound, upper_bound))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design A:\n",
      "Conversion Rate: 12.00%\n",
      "Confidence Interval: (9.15%, 14.85%)\n",
      "\n",
      "Design B:\n",
      "Conversion Rate: 15.00%\n",
      "Confidence Interval: (11.87%, 18.13%)\n",
      "\n",
      "Two-Proportion Z-Test:\n",
      "Z-Score: -1.3881\n",
      "P-Value: 0.1651\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Sample sizes and number of conversions for each design\n",
    "n_a = 500\n",
    "n_b = 500\n",
    "successes_a = 60\n",
    "successes_b = 75\n",
    "\n",
    "# Conversion rates for each design\n",
    "p_a = successes_a / n_a\n",
    "p_b = successes_b / n_b\n",
    "\n",
    "# Calculate the standard errors\n",
    "se_a = np.sqrt(p_a * (1 - p_a) / n_a)\n",
    "se_b = np.sqrt(p_b * (1 - p_b) / n_b)\n",
    "\n",
    "# Calculate the confidence intervals\n",
    "z = 1.96  # 95% confidence level (for a two-tailed test)\n",
    "ci_a = (p_a - z * se_a, p_a + z * se_a)\n",
    "ci_b = (p_b - z * se_b, p_b + z * se_b)\n",
    "\n",
    "# Perform the two-proportion z-test\n",
    "count = np.array([successes_a, successes_b])\n",
    "nobs = np.array([n_a, n_b])\n",
    "z_stat, p_value = sm.stats.proportions_ztest(count, nobs)\n",
    "\n",
    "# Print the results\n",
    "print(\"Design A:\")\n",
    "print(\"Conversion Rate: {:.2%}\".format(p_a))\n",
    "print(\"Confidence Interval: ({:.2%}, {:.2%})\".format(ci_a[0], ci_a[1]))\n",
    "print()\n",
    "\n",
    "print(\"Design B:\")\n",
    "print(\"Conversion Rate: {:.2%}\".format(p_b))\n",
    "print(\"Confidence Interval: ({:.2%}, {:.2%})\".format(ci_b[0], ci_b[1]))\n",
    "print()\n",
    "\n",
    "print(\"Two-Proportion Z-Test:\")\n",
    "print(\"Z-Score: {:.4f}\".format(z_stat))\n",
    "print(\"P-Value: {:.4f}\".format(p_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Proportion Z-Test:\n",
      "Z-Score: -1.3881\n",
      "P-Value: 0.1651\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Sample sizes and number of conversions for each design\n",
    "n_a = 500\n",
    "n_b = 500\n",
    "successes_a = 60\n",
    "successes_b = 75\n",
    "\n",
    "# Conversion rates for each design\n",
    "p_a = successes_a / n_a\n",
    "p_b = successes_b / n_b\n",
    "\n",
    "# Perform the two-proportion z-test\n",
    "count = np.array([successes_a, successes_b])\n",
    "nobs = np.array([n_a, n_b])\n",
    "z_stat, p_value = sm.stats.proportions_ztest(count, nobs)\n",
    "\n",
    "# Print the results\n",
    "print(\"Two-Proportion Z-Test:\")\n",
    "print(\"Z-Score: {:.4f}\".format(z_stat))\n",
    "print(\"P-Value: {:.4f}\".format(p_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group A:\n",
      "Conversion Rate: 16.00%\n",
      "Confidence Interval: [12.79%, 19.21%]\n",
      "\n",
      "Group B:\n",
      "Conversion Rate: 15.71%\n",
      "Confidence Interval: [13.02%, 18.41%]\n",
      "\n",
      "Two-Proportion Z-Test:\n",
      "Z-Score: 0.1337\n",
      "P-Value: 0.8937\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Sample sizes and number of conversions for each group\n",
    "n_a = 500\n",
    "n_b = 700\n",
    "successes_a = 80\n",
    "successes_b = 110\n",
    "\n",
    "# Conversion rates for each group\n",
    "p_a = successes_a / n_a\n",
    "p_b = successes_b / n_b\n",
    "\n",
    "# Perform the two-proportion z-test\n",
    "count = [successes_a, successes_b]\n",
    "nobs = [n_a, n_b]\n",
    "z_stat, p_value = sm.stats.proportions_ztest(count, nobs)\n",
    "\n",
    "# Calculate the confidence intervals\n",
    "ci_a = sm.stats.proportion_confint(successes_a, n_a)\n",
    "ci_b = sm.stats.proportion_confint(successes_b, n_b)\n",
    "\n",
    "# Print the results\n",
    "print(\"Group A:\")\n",
    "print(\"Conversion Rate: {:.2%}\".format(p_a))\n",
    "print(\"Confidence Interval: [{:.2%}, {:.2%}]\".format(ci_a[0], ci_a[1]))\n",
    "print()\n",
    "\n",
    "print(\"Group B:\")\n",
    "print(\"Conversion Rate: {:.2%}\".format(p_b))\n",
    "print(\"Confidence Interval: [{:.2%}, {:.2%}]\".format(ci_b[0], ci_b[1]))\n",
    "print()\n",
    "\n",
    "print(\"Two-Proportion Z-Test:\")\n",
    "print(\"Z-Score: {:.4f}\".format(z_stat))\n",
    "print(\"P-Value: {:.4f}\".format(p_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group A:\n",
      "Mean score: 75.00\n",
      "Confidence Interval: [73.04, 76.96]\n",
      "\n",
      "Group B:\n",
      "Mean score: 80.00\n",
      "Confidence Interval: [77.60, 82.40]\n",
      "\n",
      "Two-Sample T-Test:\n",
      "T-Statistic: -2.9269\n",
      "P-Value: 0.0037\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Group A\n",
    "n_a = 100\n",
    "mean_a = 75\n",
    "std_a = 10\n",
    "\n",
    "# Group B\n",
    "n_b = 150\n",
    "mean_b = 80\n",
    "std_b = 15\n",
    "\n",
    "# Calculate the confidence intervals\n",
    "ci_a = stats.norm.interval(0.95, loc=mean_a, scale=std_a / np.sqrt(n_a))\n",
    "ci_b = stats.norm.interval(0.95, loc=mean_b, scale=std_b / np.sqrt(n_b))\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind_from_stats(mean_a, std_a, n_a, mean_b, std_b, n_b)\n",
    "\n",
    "# Print the results\n",
    "print(\"Group A:\")\n",
    "print(\"Mean score: {:.2f}\".format(mean_a))\n",
    "print(\"Confidence Interval: [{:.2f}, {:.2f}]\".format(ci_a[0], ci_a[1]))\n",
    "print()\n",
    "\n",
    "print(\"Group B:\")\n",
    "print(\"Mean score: {:.2f}\".format(mean_b))\n",
    "print(\"Confidence Interval: [{:.2f}, {:.2f}]\".format(ci_b[0], ci_b[1]))\n",
    "print()\n",
    "\n",
    "print(\"Two-Sample T-Test:\")\n",
    "print(\"T-Statistic: {:.4f}\".format(t_stat))\n",
    "print(\"P-Value: {:.4f}\".format(p_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
